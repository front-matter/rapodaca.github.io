---
title: The Horrifying Future of Scientific Communication
summary: "Technological change has a way of making fools out of experts and experts out of fools. One of the reasons that evaluating the future impact of new technologies is so difficult is that those with the greatest potential often start out looking - and acting - like junk. They can't initially do the job nearly as well as the technologies they end up replacing. They are written off as toys."
disqus: true
published: "2013-05-08T00:00:00.000Z"
---

Technological change has a way of making fools out of experts and experts out of fools. One of the reasons that evaluating the future impact of new technologies is so difficult is that those with the greatest potential often start out looking - and acting - like junk. They can't initially do the job nearly as well as the technologies they end up replacing. They are written off as toys.

But a small number of these toy technologies have two remarkable qualities: (1) they are much cheaper or easier to use; and (2) they improve at a rate much faster than the competition. Over time, their performance is more than enough for even the most demanding uses, at which point the new technology dominates. [Disruptive Innovation](http://en.wikipedia.org/wiki/Disruptive_technology) is the process of cheap, low-quality products ultimately displacing expensive, high-quality products, typically ruining the prospects of organizations caught on the losing side.

[![Disruptive Innovation](/images/posts/disruptive-innovation.gif "Disruptive Innovation")](http://en.wikipedia.org/wiki/Disruptive_technology)

[Examples](http://www.claytonchristensen.com/key-concepts/) of Disruptive Innovation are found throughout technical fields and can take the form of products (personal computer vs. smartphone), services (snail mail vs. email), ways of delivering goods and services (Blockbuster vs. Netflix), and standards (Flash vs. HTML5).

# Disrupting the Business of Scientific Communication

Although it's possible that scientific communication is somehow immune to the forces of disruption found just about everywhere technology exists, it seems unlikely. Still, it hasn't happened yet.

One explanation could be the unusually high value placed on quality by both consumers (readers) and producers (authors). For example, consider the consistency with which scientists in any discipline can rank the relative face-value quality of an article based merely on the title of the journal it appears in. These perceptions are reinforced by a feedback mechanism in which scientists themselves rank the quality of their own work and select a journal for manuscript submission accordingly.

Clearly, electronic journal distribution marked a major turning point. But this advance represents a *sustaining* innovation: the quality of an existing product improved, allowing market leaders to grow their businesses by doing more or less what they've always done. One confirmation is that [scientific journals are getting *more* expensive every year](http://lj.libraryjournal.com/2013/04/publishing/the-winds-of-change-periodicals-price-survey-2013/), not less, despite the fact that few print journals remain.

<div class="videowrapper">
  <iframe src="https://www.youtube.com/embed/qDrMAzCHFUU" allowfullscreen></iframe>
</div>

Although it's impossible to say what specific form a true disruptive innovation in scientific communication will take technically, it may be recognized through its qualities and effects:

1.  It will be *much* cheaper or easier to use.
2.  It will be demonstrably worse in one or more ways.
3.  Its low cost and/or ease of use will attract large numbers of new participants from the fringes of science or scientific disciplines.
4.  It may be criticized as a poor replacement for scientific journals, and possibly dangerous.
5.  A path to rapidly improve the things it does poorly or obviate their importance is already available or will be soon.
6.  It may be created from off-the-shelf components.

It seems counterintuitive: to discover the future of scientific communication today, begin by sifting through the cheapest, simplest, lowest-quality replacements currently available. Be sure the options would appeal to large numbers of scientists and sci-curious left on the sidelines by the current system. Then narrow the list to those approaches with the greatest potential for rapid, sustained improvement.

# Open Access

<div class="videowrapper">
  <iframe src="https://www.youtube.com/embed/L5rVH1KGBCY" allowfullscreen></iframe>
</div>

Open Access publishers are sometimes accused of lowering publication standards, thereby lowering the quality articles being published. A recent example comes courtesy of [Derek Lowe](http://pipeline.corante.com/) in a critique of a paper linking the active ingredient in a widely-used pesticide to "pretty much every chronic illness in humans." [The last paragraph](http://pipeline.corante.com/archives/2013/04/30/is_glyphosate_poisoning_everyone.php) contains this perspective on the Open Access journal publisher, [MDPI](http://www.mdpi.com/):

> But really, all you need to know is that MDPI is the same family of "journals" that published the (in)famous Andrulis "[Gyres are the key to everything!](http://pipeline.corante.com/archives/2012/01/30/the_key_to_everything_not_quite.php)" paper. And then made all kinds of [implausible noises](http://pipeline.corante.com/archives/2012/02/03/how_the_andrulis_paper_got_published.php) about layers of peer review afterwards. No, this is one of the real problems with sleazy "open-access" journals. They give the whole idea of open-access publishing a [black eye](http://pipeline.corante.com/archives/2013/02/22/what_if_the_journal_disappears.php), and they open the floodgates to whatever ridiculous crap comes in, which then gets "peer reviewed" and "published" in an "actual scientific journal", where it can fool the credulous and mislead the uninformed.

Given that the quality of MDPI and other Open Access publishers is apparently lower than others, could we be looking at an early-stage marketplace disruption? Let's take stock:

1.  **Much cheaper or easier to use?** MDPI makes money by assessing authors an [Article Processing Charge](http://www.mdpi.com/about/apc) ranging from gratis to 1800 Swiss francs (~US $1900). In exchange, articles are available to [readers without subscription cost](http://www.mdpi.com/about/openaccess). Although the charge to authors is not very much less than other publishers offering OA distribution, the cost to readers is much less. There's little apparent difference in ease of publication, although ease of reading is vastly improved. Conclusion: **maybe**.
2.  **Demonstrably worse?** Authors of papers appearing in MDPI journals can expect none of the prestige that authors of *Science* papers enjoy. [Imprimatur matters](/articles/2012/01/18/digital-destruction-in-scientific-publishing-why-this-scientist-supports-the-research-works-act-hr-3699/). Likewise, readers of MDPI journal articles will likely approach any new article with either no knowledge of the publisher or a negative impression. Conclusion: **yes**.
3.  **Attracts fringe elements?** The paper criticized by Lowe was authored not by trained research toxicologists, but by an "[Independent Scientist and Consultant](http://www.linkedin.com/pub/anthony-samsel/23/665/605)" and a computer scientist with a bachelor degree in biophysics. Conclusion: **yes**.
4.  **Criticized as dangerous?** Lowe [isn't alone](http://academia.stackexchange.com/questions/5466/is-mdpi-a-reputable-academic-publisher) in his criticism of MDPI. If anything, there seems to be an [inherent bias](http://www.dispatch.com/content/stories/science/2013/04/28/open-access-science-journals-affect-credibility.html) against Open Access for the way it opens lines of communication previously closed off by editorial policy. Conclusion: **yes**.
5.  **Path for improvement?** If there is a way for upstart Open Access journals to improve and sustainably increase quality while keeping costs under control, it's [not obvious at this point](http://www.michaeleisen.org/blog/?p=1346). Conclusion: **no**.
6.  **Built with off-the-shelf components?** I'm not familiar with how MDPI has built its platform. It wouldn't be hard to replicate the technical side given the availability of turnkey services such as [Scholastica](https://scholasticahq.com/). Building an editorial board and network of peer-reviewers, on the other hand, would be a challenge. Conclusion: **no**.

Being worse and a little cheaper isn't enough for disruptive innovation. Many early-stage products start out looking cheap and ineffective. A steep, sustainable trajectory for improvement separates those that will remake industries.

A major problem with MDPI and other Open Access publishers is that they retain most of the practices and associated costs of established publishers: editorial boards and pre-publication peer review. These costs take the form of both money and time to publication. For this reason, it's not that much less expensive or difficult to publish in MDPI than, say, [ACS Publications](http://pubs.acs.org/userimages/ContentEditor/1218220609981/authorchoice_form.pdf). In some ways, MDPI and some other Open Access Publishers have simply created a somewhat less expensive product missing one critical feature: brand-name recognition.

Open Access may turn out to be the ultimate sustaining innovation for established publishers (although I've [suggested otherwise in the past](http://localhost:8000/articles/2006/11/16/electric-cars-and-open-access/)). By transferring publication costs from reader to author, publishers can maintain current profit margins, offer a far more accessible product to readers, and continue to attract high-quality manuscripts by leveraging brand-names built in the previous print era. Whether publishers willingly adapt or are forced by [government mandate](http://www.the-scientist.com/?articles.view/articleNo/34517/title/Obama-Mandates-Expanded-Access/), the result will be the same.

# Defenders of Scientific Integrity

The traditional mission of scientific journal publisher was threefold: (1) to assure quality; (2) convert manuscripts into publication-ready format; and (3) to physically distribute printed articles.

The rise of desktop publishing long ago rendered Part (2) of the publisher mission obsolete.

The Internet has in turn rendered Part (3) of the publisher's mission obsolete. The often-cited need to ensure continued electronic distribution of the scientific record is doubtful at best given [non-restrictive licensing](http://creativecommons.org/licenses/) coupled with ever-contracting prices of Web servers, bandwidth, and permanent storage.

It's hardly surprising that subscriber-pays scientific publishers have focused on the one service they now offer that has not become dirt cheap: quality assurance.

All of this has led some to reconsider the publisher value proposition. They argue that journals actually do a lousy job at protecting science from plagiarism, fraudulent claims, erroneous conclusions, and unrepeatable procedures. As evidence, they point to numerous cases described on sites such as [Retraction Watch](http://retractionwatch.wordpress.com/). Even worse, the more successful and established journals operate under a shroud of semi-secrecy resulting from [high access fees](http://lj.libraryjournal.com/2013/04/publishing/the-winds-of-change-periodicals-price-survey-2013/).

According to [Michael Eisen](http://www.michaeleisen.org/blog/?p=1346), co-founder of [PLOS](http://www.plos.org/), science suffers from lack of honest debate around scientific communication and an inability to adapt to a world in which the rules have changed:

> So, while it is a nice idea to imagine peer review as defender of scientific integrity – it isn’t. Flaws in a paper are far more often uncovered after the paper is published than in peer review. And yet, because we have a system that places so much emphasis on where a paper is published, we have no effective way to annotate previously published papers that turn out to be wrong.

Could it be that our faith in journal publishers and particularly in pre-publication peer review is misguided? Have we scientists and the public at large been lulled into a false sense of security every time we see the name of a flagship journal on an article header or on a CV? Could there be far more effective ways to defend science from honest mistakes, plagiarists, and crackpots with axes to grind?

# Gazing into the Future

For an idea of what a future without scientific journal publishers could look like, consider these services:

- [arXive](http://arxiv.org/), a pre-publication article archive for sciences and humanities
- [Figshare](http://figshare.com/), a repository allowing deposition of raw, unreviewed research results
- [Hacker News](https://news.ycombinator.com/), a news service without moderators
- [Stack Exchange](http://stackexchange.com/), a family of self-governing Q&A sites
- [Disqus](http://disqus.com/), a simple way to add online discussion to any Web page

What all of these highly-successful, self-sustaining, and in the case of Stack Exchange, [profitable](http://gigaom.com/2011/03/09/stack-overflow-raises-12m-now-called-stack-exchange/), services have in common is that they provide the technical underpinnings necessary to make post-publication peer review work.

Even so, the idea of a scientific paper as something of value may be losing relevance. Consider how many papers you've actually *read*, all the way through, compared to the number of papers you've skimmed for experimental details or quick conclusions. Supporting Information, combined with data mining tools, could eliminate most of the need for manuscripts in the first place. Ranking and feedback mechanisms could neutralize most of the value derived pre-publication review, just like Google made it possible to productively navigate a Web littered with far more garbage than gold.

<div class="videowrapper">
  <iframe src="https://www.youtube.com/embed/NHuC5yZeHYQ" allowfullscreen></iframe>
</div>

# Conclusions

Disruptive Innovation is a process by which previously expensive products or service become radically cheaper or easier to use. Scientific communication is an extremely inefficient and costly process that in many ways appears ripe for disruption. Although Open Access might seem to fit the bill, the more likely outcome is that existing publishers will simply adopt OA publishing practices.

Real disruptive innovation will slash the costs of creating and using scientific communication products and services. Pre-publication peer review and editorial boards will likely be the first of many casualties. In the process, scientific communication will become accessible to entirely new groups of authors and readers currently being shut out.

It goes without saying that this future scares the hell out of publishers. But it will no doubt scare the hell out of many scientists as well.